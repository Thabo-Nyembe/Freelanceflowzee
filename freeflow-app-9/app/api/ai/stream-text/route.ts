import { NextRequest, NextResponse } from 'next/server'

export async function POST(request: NextRequest) {
  try {
    const { prompt, model = 'gpt-4', stream = true, temperature = 0.7 } = await request.json()

    if (!prompt) {
      return NextResponse.json({ error: 'Prompt is required' }, { status: 400 })
    }

    if (stream) {
      // Create a streaming response
      const encoder = new TextEncoder()
      const readable = new ReadableStream({
        start(controller) {
          const chunks = [
            'Analyzing your request...\n',
            'Processing with advanced AI capabilities...\n',
            `Using model: ${model}\n`,
            'Generating comprehensive response...\n',
            `Response to: "${prompt}"\n\n`,
            'This is a streaming text response that demonstrates real-time AI text generation. ',
            'The content flows naturally as the AI processes and responds to your input. ',
            'This capability enables interactive conversations and real-time content creation.\n\n',
            'Key features of this streaming implementation:\n',
            '• Real-time text generation\n',
            '• Progressive response building\n',
            '• Low latency communication\n',
            '• Enhanced user experience\n\n',
            'Stream completed successfully.'
          ]

          let index = 0
          const interval = setInterval(() => {
            if (index < chunks.length) {
              controller.enqueue(encoder.encode(chunks[index]))
              index++
            } else {
              clearInterval(interval)
              controller.close()
            }
          }, 200)
        }
      })

      return new Response(readable, {
        headers: {
          'Content-Type': 'text/plain; charset=utf-8',
          'Transfer-Encoding': 'chunked'
        }
      })
    } else {
      // Regular response
      const response = {
        id: `stream-text-${Date.now()}`,
        text: `Stream Text Response: ${prompt}\n\nThis is a comprehensive text response generated by the streaming text API. The content is optimized for natural language processing and provides detailed, contextual information.`,
        model,
        temperature,
        timestamp: new Date().toISOString(),
        metadata: {
          streaming: false,
          contentLength: prompt.length
        }
      }

      return NextResponse.json(response)
    }
  } catch (error) {
    console.error('Stream text API error:', error)
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    )
  }
}

export async function GET() {
  return NextResponse.json({
    status: 'Stream Text API is operational',
    version: '1.0.0',
    capabilities: ['streaming', 'text-generation', 'real-time'],
    timestamp: new Date().toISOString()
  })
}
